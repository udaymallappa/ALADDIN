{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udaymallappa/ALADDIN/blob/master/DAGNN_UM_v2_jpeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RbG-Arkc7QL",
        "outputId": "893a3f32-5cda-49a4-9fbc-405e1f03417b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DAGNN' already exists and is not an empty directory.\n",
            "mv: cannot stat 'DAGNN/ogb': No such file or directory\n",
            "mv: cannot stat 'DAGNN/src': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vthost/DAGNN.git\n",
        "!mv DAGNN/ogb .\n",
        "!mv DAGNN/src ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8Xo139SbDfR",
        "outputId": "c23b4aae-1d9e-4fe2-832e-93e06567d48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "import torch; "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZLz_fF8xYM1",
        "outputId": "13c2639a-f3fb-44b6-bc99-e0f2c60447e4"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf9LvseaeB9W",
        "outputId": "e7e7c905-5ba3-463c-973f-c69ab4934a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 554 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=4a2abe45a9e29971351165edf67cd65e536c2859546e49b48a85c559f9620fa6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEzvs6FbeGPu",
        "outputId": "1c9db6b8-0ba7-412f-bd6f-f096985d1572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CIEtzBlFeKSe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import collections.abc as container_abcs\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import math, numpy as np, scipy.sparse as sp\n",
        "import torch.nn.init as init\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.modules.module import Module\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "from torch_scatter import scatter_add\n",
        "import torch_geometric\n",
        "from torch_geometric.nn.glob import *\n",
        "from torch_geometric.nn.inits import uniform, glorot\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from typing import Optional\n",
        "from torch import Tensor\n",
        "from torch_geometric.typing import OptTensor\n",
        "from torch_geometric.utils import softmax\n",
        "\n",
        "import torch.utils.data\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "from torch_geometric.data import Data, Batch\n",
        "import collections.abc as container_abcs\n",
        "\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKf4xtMOTVXn",
        "outputId": "598d0dd3-992f-497d-9bf9-e0c1c8a18c7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "-1_8DE46eOR-"
      },
      "outputs": [],
      "source": [
        "def top_sort(edge_index, graph_size):\n",
        "\n",
        "    node_ids = np.arange(graph_size, dtype=int)\n",
        "\n",
        "    node_order = np.zeros(graph_size, dtype=int)\n",
        "    unevaluated_nodes = np.ones(graph_size, dtype=bool)\n",
        "\n",
        "    parent_nodes = edge_index[0]\n",
        "    child_nodes = edge_index[1]\n",
        "\n",
        "    counter = 0\n",
        "    n = 0\n",
        "    while unevaluated_nodes.any():\n",
        "        print('In top sort index ', n)\n",
        "        \n",
        "        # Find which parent nodes have not been evaluated\n",
        "        unevaluated_mask = unevaluated_nodes[parent_nodes]\n",
        "        print('Number of parent nodes ', len(unevaluated_mask.nonzero()[0]))\n",
        "        # Find the child nodes of unevaluated parents\n",
        "        unready_children = child_nodes[unevaluated_mask]\n",
        "\n",
        "        # Mark nodes that have not yet been evaluated\n",
        "        # and which are not in the list of children with unevaluated parent nodes\n",
        "        nodes_to_evaluate = unevaluated_nodes & ~np.isin(node_ids, unready_children)\n",
        "\n",
        "        node_order[nodes_to_evaluate] = n\n",
        "        unevaluated_nodes[nodes_to_evaluate] = False\n",
        "        print('Number of unevaluated nodes ', len(nodes_to_evaluate.nonzero()[0]))\n",
        "        counter += len(nodes_to_evaluate.nonzero()[0])\n",
        "        n += 1\n",
        "    print('Total nodes  = ', counter)\n",
        "    return torch.from_numpy(node_order).long()\n",
        "\n",
        "# to be able to use pyg's batch split everything into 1-dim tensors\n",
        "def add_order_info_01(graph):\n",
        "    print('Top sort Phase 1')\n",
        "    l0 = top_sort(graph.edge_index, graph.num_nodes)\n",
        "    ei2 = torch.LongTensor([list(graph.edge_index[1]), list(graph.edge_index[0])])\n",
        "    print('Top sort Phase 2')\n",
        "    l1 = top_sort(ei2, graph.num_nodes)\n",
        "    ns = torch.LongTensor([i for i in range(graph.num_nodes)])\n",
        "\n",
        "    graph.__setattr__(\"_bi_layer_idx0\", l0)\n",
        "    graph.__setattr__(\"_bi_layer_index0\", ns)\n",
        "    graph.__setattr__(\"_bi_layer_idx1\", l1)\n",
        "    graph.__setattr__(\"_bi_layer_index1\", ns)\n",
        "\n",
        "    assert_order(graph.edge_index, l0, ns)\n",
        "    assert_order(ei2, l1, ns)\n",
        "\n",
        "def assert_order(edge_index, o, ns):\n",
        "    # already processed\n",
        "    proc = []\n",
        "    for i in range(max(o)+1):\n",
        "        # nodes in position i in order\n",
        "        l = o == i\n",
        "        l = ns[l].tolist()\n",
        "        for n in l:\n",
        "            # predecessors\n",
        "            ps = edge_index[0][edge_index[1] == n].tolist()\n",
        "            for p in ps:\n",
        "                assert p in proc\n",
        "        proc += l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "AHfof3wMeRu-"
      },
      "outputs": [],
      "source": [
        "multicls_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, device, loader, optimizer, args, evaluator):\n",
        "    model.train()\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    loss_accum = 0\n",
        "    print('Inside training module...')\n",
        "\n",
        "    add_order_info_01(loader)#why this ? @chester\n",
        "    batch = loader\n",
        "    print('Batch === ' , batch)\n",
        "    if batch:\n",
        "        print('Before Pred')\n",
        "        pred = model(batch)\n",
        "        print('Pred done')\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        targ = torch.cat([batch[i].len_longest_path.to(device) for i in range(len(batch))], dim=0)\n",
        "\n",
        "        loss = multicls_criterion(pred, targ.to(torch.long))  #batch.y.view(-1, ))\n",
        "        loss.backward()\n",
        "        if clip > 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_accum += loss.item()\n",
        "\n",
        "        y_true.append(targ.view(-1,1).detach().cpu())\n",
        "        y_pred.append(torch.argmax(pred.detach(), dim=1).view(-1, 1).cpu())\n",
        "\n",
        "    y_true = torch.cat(y_true, dim=0).numpy()\n",
        "    y_pred = torch.cat(y_pred, dim=0).numpy()\n",
        "    #print(y_true)\n",
        "    #print(y_pred)\n",
        "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
        "    return loss_accum / (step + 1)\n",
        "\n",
        "def eval(model, device, loader, evaluator):\n",
        "    model.eval()\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
        "        # one b(atch) per device\n",
        "        #batch = [batch[i] for i in range(len(batch)) if not batch[i].x.shape[0] == 1]\n",
        "        [add_order_info_01(b) for b in batch if not b.x.shape[0] == 1 and not b.batch[-1] == 0 ]\n",
        "        batch = [b for b in batch if not b.x.shape[0] == 1]\n",
        "        if batch:\n",
        "            with torch.no_grad():\n",
        "                pred = model(batch)\n",
        "            # m = [b.len_longest_path.detach().cpu() for b in batch]\n",
        "            # d = []\n",
        "            # for b in batch:\n",
        "            #     d += b.to_data_list()\n",
        "            # d = [dd.node_depth.max().item() for dd in d]\n",
        "            y_true1 = [batch[i].len_longest_path.view(-1,1).detach().cpu() for i in range(len(batch))]\n",
        "            y_true += y_true1\n",
        "\n",
        "            y_pred.append(torch.argmax(pred.detach(), dim = 1).view(-1,1).cpu())\n",
        "\n",
        "\n",
        "    y_pred = torch.cat(y_pred, dim=0)\n",
        "    y_true = torch.cat(y_true, dim=0).view(y_pred.shape)\n",
        "    y_true = y_true.numpy()\n",
        "    y_pred = y_pred.numpy()\n",
        "    # print(y_true)\n",
        "    # print(y_pred)\n",
        "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "    return evaluator.eval(input_dict)\n",
        "\n",
        "def init_model(args, node_encoder, numclass=275):\n",
        "  n = 1\n",
        "  m = 1\n",
        "  model = DAGNN(num_vocab=n, max_seq_len=m, emb_dim=emb_dim,\n",
        "              hidden_dim=emb_dim, out_dim=None, encoder=node_encoder,\n",
        "              w_edge_attr=ea, num_layers=dagnn_layers, bidirectional=bidir,\n",
        "              agg=agg, mapper_bias=mapper_bias > 0,\n",
        "              out_wx=out_wx > 0, out_pool_all=pool_all, out_pool=pool,\n",
        "              dropout=dropout, num_class=numclass)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJFT7dmExSJi"
      },
      "outputs": [],
      "source": [
        "from ogb.graphproppred.dataset import GraphPropPredDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lsu6Lyikxy4e"
      },
      "outputs": [],
      "source": [
        "from ogb.graphproppred import Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef8XA-GByj11"
      },
      "outputs": [],
      "source": [
        "#from ogb.graphproppred.dataset_pyg import PygGraphPropPredDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from ogb.io.read_graph_raw import read_csv_graph_raw, read_csv_heterograph_raw, read_binary_graph_raw, read_binary_heterograph_raw\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from src.utils_dag import add_order_info_01  # VT\n",
        "\n",
        "\n",
        "def read_graph_pyg(raw_dir, add_inverse_edge = False, additional_node_files = [], additional_edge_files = [], binary = False):\n",
        "\n",
        "    if binary:\n",
        "        # npz\n",
        "        graph_list = read_binary_graph_raw(raw_dir, add_inverse_edge)\n",
        "    else:\n",
        "        # csv\n",
        "        graph_list = read_csv_graph_raw(raw_dir, add_inverse_edge, additional_node_files = additional_node_files, additional_edge_files = additional_edge_files)\n",
        "    \n",
        "    pyg_graph_list = []\n",
        "\n",
        "    print('XXXX: Custom Code Alert XXXX Converting graphs into PyG objects...')\n",
        "\n",
        "    gind = 0\n",
        "    for graph in tqdm(graph_list):\n",
        "        if gind > 100:\n",
        "            break\n",
        "        gind += 1\n",
        "        print('Processing graph index : ', gind)\n",
        "        print(graph.items())\n",
        "        print(graph['edge_index'])\n",
        "        print(graph['num_nodes'])\n",
        "\n",
        "\n",
        "        g = Data()\n",
        "        g.__num_nodes__ = graph['num_nodes']\n",
        "        g.edge_index = torch.from_numpy(graph['edge_index'])\n",
        "\n",
        "        del graph['num_nodes']\n",
        "        del graph['edge_index']\n",
        "\n",
        "        if graph['edge_feat'] is not None:\n",
        "            g.edge_attr = torch.from_numpy(graph['edge_feat'])\n",
        "            del graph['edge_feat']\n",
        "\n",
        "        if graph['node_feat'] is not None:\n",
        "            g.x = torch.from_numpy(graph['node_feat'])\n",
        "            del graph['node_feat']\n",
        "\n",
        "        for key in additional_node_files:\n",
        "            g[key] = torch.from_numpy(graph[key])\n",
        "            del graph[key]\n",
        "\n",
        "        for key in additional_edge_files:\n",
        "            g[key] = torch.from_numpy(graph[key])\n",
        "            del graph[key]\n",
        "\n",
        "        pyg_graph_list.append(g)\n",
        "\n",
        "        add_order_info_01(g)  # DAGNN\n",
        "        # length of longest path\n",
        "        # layer ids start with 0 so max, gives actual path length and -1 is not necessary\n",
        "        g.len_longest_path = float(torch.max(g._bi_layer_idx0).item())\n",
        "\n",
        "    return pyg_graph_list\n",
        "\n",
        "\n",
        "def read_heterograph_pyg(raw_dir, add_inverse_edge = False, additional_node_files = [], additional_edge_files = [], binary = False):\n",
        "\n",
        "    if binary:\n",
        "        # npz\n",
        "        graph_list = read_binary_heterograph_raw(raw_dir, add_inverse_edge)\n",
        "    else:\n",
        "        # csv\n",
        "        graph_list = read_csv_heterograph_raw(raw_dir, add_inverse_edge, additional_node_files = additional_node_files, additional_edge_files = additional_edge_files)\n",
        "\n",
        "    pyg_graph_list = []\n",
        "\n",
        "    print('Converting graphs into PyG objects...')\n",
        "\n",
        "    for graph in tqdm(graph_list):\n",
        "        g = Data()\n",
        "        \n",
        "        g.__num_nodes__ = graph['num_nodes_dict']\n",
        "        g.num_nodes_dict = graph['num_nodes_dict']\n",
        "\n",
        "        # add edge connectivity\n",
        "        g.edge_index_dict = {}\n",
        "        for triplet, edge_index in graph['edge_index_dict'].items():\n",
        "            g.edge_index_dict[triplet] = torch.from_numpy(edge_index)\n",
        "\n",
        "        del graph['edge_index_dict']\n",
        "\n",
        "        if graph['edge_feat_dict'] is not None:\n",
        "            g.edge_attr_dict = {}\n",
        "            for triplet in graph['edge_feat_dict'].keys():\n",
        "                g.edge_attr_dict[triplet] = torch.from_numpy(graph['edge_feat_dict'][triplet])\n",
        "\n",
        "            del graph['edge_feat_dict']\n",
        "\n",
        "        if graph['node_feat_dict'] is not None:\n",
        "            g.x_dict = {}\n",
        "            for nodetype in graph['node_feat_dict'].keys():\n",
        "                g.x_dict[nodetype] = torch.from_numpy(graph['node_feat_dict'][nodetype])\n",
        "\n",
        "            del graph['node_feat_dict']\n",
        "\n",
        "        for key in additional_node_files:\n",
        "            g[key] = {}\n",
        "            for nodetype in graph[key].keys():\n",
        "                g[key][nodetype] = torch.from_numpy(graph[key][nodetype])\n",
        "\n",
        "            del graph[key]\n",
        "\n",
        "        for key in additional_edge_files:\n",
        "            g[key] = {}\n",
        "            for triplet in graph[key].keys():\n",
        "                g[key][triplet] = torch.from_numpy(graph[key][triplet])\n",
        "\n",
        "            del graph[key]\n",
        "\n",
        "        pyg_graph_list.append(g)\n",
        "\n",
        "    return pyg_graph_list"
      ],
      "metadata": {
        "id": "pB5D2ctRmPnW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import InMemoryDataset\n",
        "import pandas as pd\n",
        "import shutil, os\n",
        "import os.path as osp\n",
        "import torch\n",
        "import numpy as np\n",
        "from ogb.utils.url import decide_download, download_url, extract_zip\n",
        "#from ogb.io.read_graph_pyg import read_graph_pyg"
      ],
      "metadata": {
        "id": "wTK6Hj2sj54O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "4YgQ3B4ewrOF"
      },
      "outputs": [],
      "source": [
        "### importing OGB\n",
        "\n",
        "\n",
        "import torch.multiprocessing\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "args = None\n",
        "\n",
        "dataset=\"ogbg-code2\"\n",
        "\n",
        "filename = \"name\"\n",
        "dir_data='./'\n",
        "\n",
        "dir_results = 'DIR_RESULTS' \n",
        "dir_save = 'DIR_SAVED_MODELS'\n",
        "gnn = 'dagnn'\n",
        "device=0\n",
        "\n",
        "lr=1e-3\n",
        "clip=0.25\n",
        "\n",
        "numclass=275\n",
        "emb_dim=300\n",
        "dagnn_layers=2\n",
        "batch_size=160\n",
        "num_workers = 0\n",
        "bidir=1\n",
        "ea=1\n",
        "agg='attn_h'\n",
        "dropout=0\n",
        "pool_all=0\n",
        "pool='max'\n",
        "mapper_bias=1\n",
        "out_wx=0\n",
        "\n",
        "checkpoint=\"\"\n",
        "checkpointing=0\n",
        "\n",
        "folds=1\n",
        "epochs=1000\n",
        "lay=5\n",
        "patience=10\n",
        "\n",
        "train_idx='train10' # use \"\" to run over the full dataset\n",
        "\n",
        "device = torch.device(\"cuda:\" + str(device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "os.makedirs(dir_results, exist_ok=True)\n",
        "os.makedirs(dir_save, exist_ok=True)\n",
        "\n",
        "train_file = os.path.join(dir_results, filename + '_train.csv')\n",
        "if not os.path.exists(train_file):\n",
        "    with open(train_file, 'w') as f:\n",
        "        f.write(\"fold,epoch,loss,train,valid,test\\n\")\n",
        "res_file = os.path.join(dir_results, filename + '.csv')\n",
        "if not os.path.exists(res_file):\n",
        "    with open(res_file, 'w') as f:\n",
        "        f.write(\"fold,epoch,bestv_train,bestv_valid,bestv_test\\n\")\n",
        "\n",
        "### automatic dataloading and splitting\n",
        "#dataset = PygGraphPropPredDataset(name=dataset, root=\"dataset\" if dir_data is None else dir_data)\n",
        "#dataset = PygNodePropPredDataset(name=dataset, root=\"dataset\" if dir_data is None else dir_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.data as Data\n",
        "edge = np.loadtxt('/content/drive/MyDrive/dagnn_code/jpeg_edge_new.txt')\n",
        "nx = np.loadtxt('/content/drive/MyDrive/dagnn_code/jpeg_encoder_node_x.txt')\n",
        "ny = np.loadtxt('/content/drive/MyDrive/dagnn_code/jpeg_encoder_node_y.txt')\n",
        "\n",
        "\n",
        "edge_tf = torch.tensor(edge.T, dtype=int)\n",
        "nx_tf = torch.tensor(nx)\n",
        "#ny_tf = torch.tensor(ny)\n",
        "ny_tf = torch.randint(1,4, (nx_tf.shape[0],1))#dummy labels randomly created\n",
        "D = Data.Data(x=nx_tf,edge_index=edge_tf, y=ny_tf)#, graph_size=nx.shape[0])"
      ],
      "metadata": {
        "id": "FKLkZGfsWJGN"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ny_tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwcIoq_sLPFo",
        "outputId": "492c88a9-2b7e-45cc-b0c4-e092544e26f4"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3],\n",
              "        [2],\n",
              "        [3],\n",
              "        ...,\n",
              "        [3],\n",
              "        [3],\n",
              "        [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title sample 12 node DAG\n",
        "nx = np.random.rand(12,2)\n",
        "ny = np.random.rand(12,1)\n",
        "edge = np.random.rand(10,2)\n",
        "edge[0] = [1,2]\n",
        "edge[1] = [2,3]\n",
        "edge[2] = [5,6]\n",
        "edge[3] = [3,4]\n",
        "edge[4] = [6,7]\n",
        "edge[5] = [7,11]\n",
        "edge[6] = [9,10]\n",
        "edge[7] = [10,11]\n",
        "edge[8] = [8,9]\n",
        "edge[9] = [0,1]\n",
        "edge_tf = torch.tensor(edge.T, dtype=int)\n",
        "nx_tf = torch.tensor(nx)\n",
        "ny_tf = torch.tensor(ny)\n",
        "D = Data.Data(x=nx_tf,edge_index=edge_tf, y=ny_tf)#, graph_size=nx.shape[0])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1sJzkSxQyZ7U"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts = top_sort(D.edge_index, nx.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9nJJpIoM8h2",
        "outputId": "b3b1a756-8882-43e5-8dfb-d92a645980fd"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In top sort index  0\n",
            "Number of parent nodes  107045\n",
            "Number of unevaluated nodes  5119\n",
            "In top sort index  1\n",
            "Number of parent nodes  95207\n",
            "Number of unevaluated nodes  2668\n",
            "In top sort index  2\n",
            "Number of parent nodes  89265\n",
            "Number of unevaluated nodes  1118\n",
            "In top sort index  3\n",
            "Number of parent nodes  84099\n",
            "Number of unevaluated nodes  1947\n",
            "In top sort index  4\n",
            "Number of parent nodes  74804\n",
            "Number of unevaluated nodes  4776\n",
            "In top sort index  5\n",
            "Number of parent nodes  62185\n",
            "Number of unevaluated nodes  6541\n",
            "In top sort index  6\n",
            "Number of parent nodes  51012\n",
            "Number of unevaluated nodes  5965\n",
            "In top sort index  7\n",
            "Number of parent nodes  41468\n",
            "Number of unevaluated nodes  4429\n",
            "In top sort index  8\n",
            "Number of parent nodes  34541\n",
            "Number of unevaluated nodes  3486\n",
            "In top sort index  9\n",
            "Number of parent nodes  28648\n",
            "Number of unevaluated nodes  3169\n",
            "In top sort index  10\n",
            "Number of parent nodes  23582\n",
            "Number of unevaluated nodes  2976\n",
            "In top sort index  11\n",
            "Number of parent nodes  19130\n",
            "Number of unevaluated nodes  2794\n",
            "In top sort index  12\n",
            "Number of parent nodes  15559\n",
            "Number of unevaluated nodes  2223\n",
            "In top sort index  13\n",
            "Number of parent nodes  12775\n",
            "Number of unevaluated nodes  1734\n",
            "In top sort index  14\n",
            "Number of parent nodes  10632\n",
            "Number of unevaluated nodes  1328\n",
            "In top sort index  15\n",
            "Number of parent nodes  8746\n",
            "Number of unevaluated nodes  1099\n",
            "In top sort index  16\n",
            "Number of parent nodes  7030\n",
            "Number of unevaluated nodes  971\n",
            "In top sort index  17\n",
            "Number of parent nodes  5631\n",
            "Number of unevaluated nodes  820\n",
            "In top sort index  18\n",
            "Number of parent nodes  4432\n",
            "Number of unevaluated nodes  692\n",
            "In top sort index  19\n",
            "Number of parent nodes  3477\n",
            "Number of unevaluated nodes  555\n",
            "In top sort index  20\n",
            "Number of parent nodes  2718\n",
            "Number of unevaluated nodes  519\n",
            "In top sort index  21\n",
            "Number of parent nodes  2008\n",
            "Number of unevaluated nodes  512\n",
            "In top sort index  22\n",
            "Number of parent nodes  1390\n",
            "Number of unevaluated nodes  457\n",
            "In top sort index  23\n",
            "Number of parent nodes  880\n",
            "Number of unevaluated nodes  413\n",
            "In top sort index  24\n",
            "Number of parent nodes  502\n",
            "Number of unevaluated nodes  302\n",
            "In top sort index  25\n",
            "Number of parent nodes  258\n",
            "Number of unevaluated nodes  220\n",
            "In top sort index  26\n",
            "Number of parent nodes  102\n",
            "Number of unevaluated nodes  132\n",
            "In top sort index  27\n",
            "Number of parent nodes  42\n",
            "Number of unevaluated nodes  52\n",
            "In top sort index  28\n",
            "Number of parent nodes  8\n",
            "Number of unevaluated nodes  33\n",
            "In top sort index  29\n",
            "Number of parent nodes  1\n",
            "Number of unevaluated nodes  7\n",
            "In top sort index  30\n",
            "Number of parent nodes  0\n",
            "Number of unevaluated nodes  1\n",
            "Total nodes  =  57058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title top sort for graphs (validation purpose)\n",
        "#Python program to print topological sorting of a DAG\n",
        "from collections import defaultdict\n",
        " \n",
        "#Class to represent a graph\n",
        "class Graph:\n",
        "    def __init__(self,vertices):\n",
        "        self.graph = defaultdict(list) #dictionary containing adjacency List\n",
        "        self.V = vertices #No. of vertices\n",
        " \n",
        "    # function to add an edge to graph\n",
        "    def addEdge(self,u,v):\n",
        "        self.graph[u].append(v)\n",
        " \n",
        "    # A recursive function used by topologicalSort\n",
        "    def topologicalSortUtil(self,v,visited,stack):\n",
        " \n",
        "        # Mark the current node as visited.\n",
        "        visited[v] = True\n",
        " \n",
        "        # Recur for all the vertices adjacent to this vertex\n",
        "        for i in self.graph[v]:\n",
        "            if visited[i] == False:\n",
        "                self.topologicalSortUtil(i,visited,stack)\n",
        " \n",
        "        # Push current vertex to stack which stores result\n",
        "        stack.insert(0,v)\n",
        " \n",
        "    # The function to do Topological Sort. It uses recursive\n",
        "    # topologicalSortUtil()\n",
        "    def topologicalSort(self):\n",
        "        # Mark all the vertices as not visited\n",
        "        visited = [False]*self.V\n",
        "        stack =[]\n",
        " \n",
        "        # Call the recursive helper function to store Topological\n",
        "        # Sort starting from all vertices one by one\n",
        "        for i in range(self.V):\n",
        "            if visited[i] == False:\n",
        "                self.topologicalSortUtil(i,visited,stack)\n",
        " \n",
        "        # Print contents of stack\n",
        "        print(stack)\n",
        "g= Graph(12)\n",
        "g.addEdge(0,1)\n",
        "g.addEdge(1,2)\n",
        "g.addEdge(3,4)\n",
        "g.addEdge(2,3)\n",
        "g.addEdge(6,7)\n",
        "g.addEdge(5,6)\n",
        "g.addEdge(7,11)\n",
        "g.addEdge(8,9)\n",
        "g.addEdge(9,10)\n",
        "g.addEdge(10,11)\n",
        "g.topologicalSort()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "r55RaICcuFmh"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx80EQ6cO85b"
      },
      "outputs": [],
      "source": [
        "!mv /content/ogbg_code2 /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qPgINnwRRnV"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/ogbg_code2 /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "gy_9ONUnQLEi"
      },
      "outputs": [],
      "source": [
        "from utils2 import augment_edge2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHIWWBDMpLMO"
      },
      "outputs": [],
      "source": [
        "split_idx = dataset.get_idx_split()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uet6j6nJ977F",
        "outputId": "c67ac0a2-2e89-4bd6-a9ab-a7ef5f4c999e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': tensor([430793, 430794, 430795,  ..., 452738, 452739, 452740]),\n",
              " 'train': tensor([     0,      1,      2,  ..., 407973, 407974, 407975]),\n",
              " 'valid': tensor([407976, 407977, 407978,  ..., 430790, 430791, 430792])}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "5wsw0Y-4XvOE"
      },
      "outputs": [],
      "source": [
        "def init_model(args, node_encoder, numclass=275):\n",
        "  n = 1\n",
        "  m = 1\n",
        "  model = DAGNN(num_vocab=n, max_seq_len=m, emb_dim=emb_dim,\n",
        "              hidden_dim=emb_dim, out_dim=None, encoder=node_encoder,\n",
        "              w_edge_attr=ea, num_layers=dagnn_layers, bidirectional=bidir,\n",
        "              agg=agg, mapper_bias=mapper_bias > 0,\n",
        "              out_wx=out_wx > 0, out_pool_all=pool_all, out_pool=pool,\n",
        "              dropout=dropout, num_class=numclass)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "naTG5F1sYHYt"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "path = os.path.abspath('.')\n",
        "path = path[:path.rindex(\"/\")] + \"/../\"\n",
        "PATH = os.path.abspath(path)\n",
        "\n",
        "# the latter are only default values used in config\n",
        "DIR_DATA = os.path.join(PATH, 'data')\n",
        "DIR_RESULTS = os.path.join(PATH, 'results')\n",
        "DIR_SAVED_MODELS = os.path.join(PATH, 'saved_models')\n",
        "\n",
        "NA_SUM = \"add\"\n",
        "NA_MAX = \"max\"\n",
        "NA_GATED_SUM = \"gated_sum\"\n",
        "NA_SELF_ATTN_X = \"self_attn_x\"  # use xs of preds to compute weights, used to aggregate hs of preds\n",
        "NA_SELF_ATTN_H = \"self_attn_h\"\n",
        "NA_ATTN_X = \"attn_x\"  # use x and xs of preds to compute weights, used to aggregate hs of preds\n",
        "NA_ATTN_H = \"attn_h\"  # use x and hs of preds\n",
        "NA_MATTN_H = \"mattn_h\"  # use x and hs of preds\n",
        "\n",
        "P_MEAN = \"mean\"\n",
        "P_ADD = \"add\"  # do not use \"sum\" so that can be used to call tg pooling function\n",
        "P_SUM = \"sum\"  # do not use \"sum\" so that can be used to call tg pooling function\n",
        "P_MAX = \"max\"\n",
        "P_ATTN = \"attn\"\n",
        "EMB_POOLINGS = [P_MEAN, P_MAX, P_SUM]\n",
        "POOLINGS = [P_MEAN, P_MAX, P_ATTN, P_ADD]\n",
        "class DAGNN(nn.Module):\n",
        "\n",
        "    def __init__(self, num_vocab, max_seq_len, emb_dim, hidden_dim, out_dim,\n",
        "                 num_rels=2, w_edge_attr=True, num_layers=2, bidirectional=True, mapper_bias=True,  # bias only for DVAE simulation\n",
        "                 agg_x=False, agg=NA_ATTN_H, out_wx=True, out_pool_all=True, out_pool=P_MAX, encoder=None, dropout=0.0,\n",
        "                 word_vectors=None, emb_dims=[], activation=None, num_class=0, recurr=1):\n",
        "        super().__init__()\n",
        "        self.num_class = num_class\n",
        "        self.num_vocab = num_vocab\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        if agg_x and hidden_dim < emb_dim:\n",
        "            raise ValueError('Hidden dimension too small for input.')\n",
        "\n",
        "        # configuration\n",
        "        self.agg_x = agg_x  # use input states of predecessors instead of hidden ones\n",
        "        self.agg_attn = \"attn\" in agg\n",
        "        self.agg_attn_x = \"_x\" in agg\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dirs = [0, 1] if bidirectional else [0]\n",
        "        self.num_layers = num_layers\n",
        "        self.out_wx = out_wx\n",
        "        self.output_all = out_pool_all\n",
        "        self.recurr = recurr\n",
        "\n",
        "        # dimensions\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.out_hidden_dim = emb_dim * len(self.dirs) + self.hidden_dim * len(self.dirs) * num_layers if out_wx else self.hidden_dim * len(self.dirs) * num_layers  # USING UNIFY*len(self.dirs)\n",
        "        # self.out_dim = out_dim  # not needed in OGB\n",
        "\n",
        "        # initial embedding\n",
        "        self.encoder = encoder if encoder is not None else init_encoder(word_vectors, emb_dims)\n",
        "\n",
        "        # aggregate\n",
        "        # agg_x makes only sense in first NN layer we could afterwards automatically use h? but postponing this...\n",
        "        # (then add pred_dim term directly when looping over layers below)\n",
        "        num_rels = num_rels if w_edge_attr else 1\n",
        "        pred_dim = self.emb_dim if self.agg_x else self.hidden_dim\n",
        "        attn_dim = self.emb_dim if \"_x\" in agg else self.hidden_dim\n",
        "        if \"self_attn\" in agg:\n",
        "            # it wouldn't make sense to perform attention based on h when aggregating x... so no hidden_dim needed\n",
        "            self.node_aggr_0 = nn.ModuleList([\n",
        "                SelfAttnConv(attn_dim, num_relations=num_rels) for _ in range(num_layers)])\n",
        "            self.node_aggr_1 = nn.ModuleList([\n",
        "                SelfAttnConv(attn_dim, num_relations=num_rels, reverse=True) for _ in range(num_layers)])\n",
        "        elif \"attn\" in agg:\n",
        "            op = MultAttnConv if \"mattn\" in agg else AttnConv\n",
        "            self.node_aggr_0 = nn.ModuleList([\n",
        "                op(self.emb_dim if l == 0 else attn_dim, pred_dim, num_relations=num_rels, attn_dim=attn_dim) for l in range(num_layers)])\n",
        "            self.node_aggr_1 = nn.ModuleList([\n",
        "                op(self.emb_dim if l == 0 else attn_dim, pred_dim, num_relations=num_rels, attn_dim=attn_dim, reverse=True) for l in range(num_layers)])\n",
        "        elif agg == NA_GATED_SUM:\n",
        "            self.node_aggr_0 = nn.ModuleList([\n",
        "                GatedSumConv(pred_dim, num_rels, mapper_bias=mapper_bias) for _ in range(num_layers)])\n",
        "            self.node_aggr_1 = nn.ModuleList([\n",
        "                GatedSumConv(pred_dim, num_rels, mapper_bias=mapper_bias, reverse=True) for _ in range(num_layers)])\n",
        "        else:\n",
        "            node_aggr = AggConv(agg, num_rels, pred_dim)\n",
        "            self.node_aggr_0 = self.node_aggr_1 = nn.ModuleList([node_aggr for _ in range(num_layers)])  # just to have same format\n",
        "\n",
        "        # RNN\n",
        "        if recurr:\n",
        "            for i in self.dirs:\n",
        "                self.__setattr__(\"cells_{}\".format(i), nn.ModuleList(\n",
        "                    [nn.GRUCell(emb_dim if l == 0 else self.hidden_dim, self.hidden_dim) for l in range(num_layers)]))\n",
        "        else:\n",
        "            for i in self.dirs:\n",
        "                self.__setattr__(\"cells_{}\".format(i), nn.ModuleList(\n",
        "                    [nn.Linear((emb_dim if l == 0 else self.hidden_dim)+self.hidden_dim, self.hidden_dim) for l in range(num_layers)]))\n",
        "\n",
        "        # readout\n",
        "        if out_pool == P_ATTN:\n",
        "            d = int(self.out_hidden_dim/2) if self.bidirectional and not self.output_all else self.out_hidden_dim\n",
        "            self.self_attn_linear_out = torch.nn.Linear(d, 1)\n",
        "            self._readout = self._out_nodes_self_attn\n",
        "        else:\n",
        "            self._readout = getattr(torch_geometric.nn, 'global_{}_pool'.format(out_pool))\n",
        "\n",
        "        # output\n",
        "        # self.out_norm = nn.LayerNorm(self.out_hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # self.out_linear = torch.nn.Linear(self.out_hidden_dim, out_dim)\n",
        "        # self.activation = init_activation(activation, out_dim)\n",
        "\n",
        "        # OGB\n",
        "\n",
        "        if self.num_class > 0:  # classification\n",
        "            self.graph_pred_linear = torch.nn.Linear(self.out_hidden_dim, self.num_class)\n",
        "        else:\n",
        "            self.graph_pred_linear_list = torch.nn.ModuleList()\n",
        "            if self.num_vocab == 1:  # regression\n",
        "                self.graph_pred_linear_list.append(torch.nn.Sequential(\n",
        "                    torch.nn.Linear(self.out_hidden_dim, self.num_vocab), torch.nn.ReLU()))\n",
        "            else:\n",
        "                for i in range(max_seq_len):\n",
        "                    self.graph_pred_linear_list.append(torch.nn.Linear(self.out_hidden_dim, self.num_vocab))\n",
        "\n",
        "    def _out_nodes_self_attn(self, h, batch):\n",
        "        attn_weights = self.self_attn_linear_out(h)\n",
        "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "        return global_add_pool(attn_weights * h, batch)\n",
        "\n",
        "    def _get_output_nodes(self, G, reverse=0):\n",
        "        if reverse:\n",
        "            layer0 = G.bi_layer_index[0][0] == 0\n",
        "            layer0 = G.bi_layer_index[0][1][layer0]\n",
        "            return layer0\n",
        "        layer0 = G.bi_layer_index[1][0] == 0\n",
        "        layer0 = G.bi_layer_index[1][1][layer0]\n",
        "        return layer0\n",
        "\n",
        "    def forward(self, G):\n",
        "        print('Inside Forward')\n",
        "        # need to create these here since pyg's batching otherwise messes up the indices\n",
        "        G.bi_layer_index = torch.stack([\n",
        "            torch.stack([G._bi_layer_idx0, G._bi_layer_index0], dim=0),\n",
        "            torch.stack([G._bi_layer_idx1, G._bi_layer_index1], dim=0)\n",
        "        ], dim=0)\n",
        "        print('Done with bi layer indexing')\n",
        "        print(G.bi_layer_index)\n",
        "        device = G.x.device\n",
        "        num_nodes_batch = G.x.shape[0]\n",
        "        num_layers_batch = max(G.bi_layer_index[0][0]).item() + 1\n",
        "\n",
        "        G.x = self.encoder(G.x, G.node_depth.view(-1, ))\n",
        "\n",
        "        G.h = [[torch.zeros(num_nodes_batch, self.hidden_dim).to(device)\n",
        "                for _ in self.__getattr__(\"cells_{}\".format(0))] for _ in self.dirs]\n",
        "\n",
        "        for d in self.dirs:\n",
        "            for l_idx in range(num_layers_batch):\n",
        "                layer = G.bi_layer_index[d][0] == l_idx\n",
        "                layer = G.bi_layer_index[d][1][layer]\n",
        "\n",
        "                inp = G.x[layer]\n",
        "\n",
        "                if l_idx > 0:  # no predecessors at first layer\n",
        "                    le_idx = []\n",
        "                    for n in layer:\n",
        "                        ne_idx = G.edge_index[1-d] == n\n",
        "                        le_idx += [ne_idx.nonzero().squeeze(-1)]\n",
        "                    le_idx = torch.cat(le_idx, dim=-1)\n",
        "                    lp_edge_index = G.edge_index[:, le_idx]\n",
        "\n",
        "                    if self.agg_x:\n",
        "                        # it wouldn't make sense to perform attention based on h when aggregating x... so no h needed\n",
        "                        kwargs = {\"h_attn\": G.x, \"h_attn_q\": G.x} if self.agg_attn else {}  # just ignore query arg if self attn\n",
        "                        node_agg = self.__getattr__(\"node_aggr_{}\".format(d))[0]\n",
        "                        ps_h = node_agg(G.x, lp_edge_index, edge_attr=G.edge_attr[le_idx], **kwargs)[layer]\n",
        "                        # if we aggregate x...\n",
        "                        s = ps_h.shape\n",
        "                        if s[-1] < self.hidden_dim:\n",
        "                            ps_h = torch.cat([ps_h, torch.zeros(s[0], self.hidden_dim-s[1])], dim=-1)\n",
        "                        # print(G.x[lp_idx])\n",
        "                        # print(ps_h)\n",
        "\n",
        "                for i, cell in enumerate(self.__getattr__(\"cells_{}\".format(d))):\n",
        "                    if l_idx == 0:\n",
        "                        ps_h = None if self.recurr else torch.zeros(inp.shape[0], self.hidden_dim).to(device)\n",
        "                    elif not self.agg_x:\n",
        "                        kwargs = {} if not self.agg_attn else \\\n",
        "                                    {\"h_attn\": G.x, \"h_attn_q\": G.x} if self.agg_attn_x else \\\n",
        "                                    {\"h_attn\": G.h[d][i], \"h_attn_q\": G.h[d][i-1] if i > 0 else G.x}  # just ignore query arg if self attn\n",
        "                        node_agg = self.__getattr__(\"node_aggr_{}\".format(d))[i]\n",
        "                        ps_h = node_agg(G.h[d][i], lp_edge_index, edge_attr=G.edge_attr[le_idx], **kwargs)[layer]\n",
        "\n",
        "                    inp = cell(inp, ps_h) if self.recurr else cell(torch.cat([inp, ps_h], dim=1))\n",
        "                    G.h[d][i][layer] += inp\n",
        "\n",
        "        if self.bidirectional and not self.output_all:\n",
        "            index = self._get_output_nodes(G)\n",
        "            h0 = torch.cat([G.x] + [G.h[0][l] for l in range(self.num_layers)], dim=-1) if self.out_wx else \\\n",
        "                torch.cat([G.h[0][l] for l in range(self.num_layers)], dim=-1)\n",
        "            out0 = self._readout(h0[index], G.batch[index])\n",
        "            index = self._get_output_nodes(G, reverse=1)\n",
        "            h1 = torch.cat([G.x] + [G.h[1][l] for l in range(self.num_layers)], dim=-1) if self.out_wx else \\\n",
        "                torch.cat([G.h[1][l] for l in range(self.num_layers)], dim=-1)\n",
        "            out1 = self._readout(h1[index], G.batch[index])\n",
        "            out = torch.cat([out0, out1], dim=-1)\n",
        "        else:\n",
        "            G.h = torch.cat([G.x] + [G.h[d][l] for d in self.dirs for l in range(self.num_layers)], dim=-1) if self.out_wx else \\\n",
        "                torch.cat([G.h[d][l] for d in self.dirs for l in range(self.num_layers)], dim=-1) if self.bidirectional else \\\n",
        "                    torch.cat([G.h[0][l] for l in range(self.num_layers)], dim=-1)\n",
        "\n",
        "            if not self.output_all:\n",
        "                index = self._get_output_nodes(G)\n",
        "                G.h, G.batch = G.h[index], G.batch[index]\n",
        "            out = self._readout(G.h, G.batch)\n",
        "\n",
        "        # out = self.out_linear(out)  #self.out_norm(out)\n",
        "        out = self.dropout(out)\n",
        "        # return self.activation(out).squeeze(-1)\n",
        "        # return out\n",
        "\n",
        "        if self.num_class > 0:\n",
        "            return self.graph_pred_linear(out)\n",
        "\n",
        "        pred_list = []\n",
        "        for i in range(self.max_seq_len):\n",
        "            pred_list.append(self.graph_pred_linear_list[i](out))\n",
        "        return pred_list\n",
        "\n",
        "\n",
        "def init_encoder(word_vectors, emb_dim):\n",
        "    if word_vectors is not None:\n",
        "        return nn.EmbeddingBag.from_pretrained(word_vectors, freeze=True, mode=\"sum\")\n",
        "    elif len(emb_dim) > 0:\n",
        "        return nn.EmbeddingBag(emb_dim[0], emb_dim[1], mode=\"sum\")\n",
        "    return None\n",
        "\n",
        "def init_param_emb(size, device):\n",
        "    param = torch.zeros(size).to(device)\n",
        "    glorot(param)\n",
        "    # uniform(size, param)\n",
        "    return param\n",
        "\n",
        "\n",
        "class AggConv(MessagePassing):\n",
        "    def __init__(self, agg, num_relations=1, emb_dim=0, reverse=False):\n",
        "        super(AggConv, self).__init__(aggr=agg, flow='target_to_source' if reverse else 'source_to_target')\n",
        "\n",
        "        if num_relations > 1:\n",
        "            assert emb_dim > 0\n",
        "            self.edge_encoder = torch.nn.Linear(num_relations, emb_dim)  # assuming num_relations one hot encoded\n",
        "            self.wea = True\n",
        "        else:\n",
        "            self.wea = False\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr=None, **kwargs):\n",
        "        edge_embedding = self.edge_encoder(edge_attr) if self.wea else None\n",
        "        return self.propagate(edge_index, x=x, edge_attr=edge_embedding)\n",
        "\n",
        "    def message(self, x_j, edge_attr):\n",
        "        return x_j + edge_attr if self.wea else x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "class GatedSumConv(MessagePassing):  # dvae needs outdim parameter\n",
        "    def __init__(self, emb_dim, num_relations=1, mapper_bias=True, reverse=False):\n",
        "        super(GatedSumConv, self).__init__(aggr='add', flow='target_to_source' if reverse else 'source_to_target')\n",
        "\n",
        "        assert emb_dim > 0\n",
        "        if num_relations > 1:\n",
        "            self.wea = True\n",
        "            self.edge_encoder = torch.nn.Linear(num_relations, emb_dim)\n",
        "        else:\n",
        "            self.wea = False\n",
        "        self.mapper = nn.Linear(emb_dim, emb_dim, bias=mapper_bias)\n",
        "        self.gate = nn.Sequential(nn.Linear(emb_dim, emb_dim), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr=None, **kwargs):\n",
        "        edge_embedding = self.edge_encoder(edge_attr) if self.wea else None\n",
        "        return self.propagate(edge_index, x=x, edge_attr=edge_embedding)\n",
        "\n",
        "    def message(self, x_j, edge_attr):\n",
        "        h_j = x_j + edge_attr if self.wea else x_j\n",
        "        return self.gate(h_j) * self.mapper(h_j)\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "class SelfAttnConv(MessagePassing):\n",
        "    def __init__(self, emb_dim, attn_dim=0, num_relations=1, reverse=False):\n",
        "        super(SelfAttnConv, self).__init__(aggr='add', flow='target_to_source' if reverse else 'source_to_target')\n",
        "\n",
        "        assert emb_dim > 0\n",
        "        attn_dim = attn_dim if attn_dim > 0 else emb_dim\n",
        "        if num_relations > 1:\n",
        "            self.wea = True\n",
        "            self.edge_encoder = torch.nn.Linear(num_relations, attn_dim)\n",
        "        else:\n",
        "            self.wea = False\n",
        "        self.attn_lin = nn.Linear(attn_dim, 1)\n",
        "\n",
        "    # h_attn, edge_attr are optional\n",
        "    def forward(self, h, edge_index, edge_attr=None, h_attn=None, **kwargs):\n",
        "        edge_embedding = self.edge_encoder(edge_attr) if self.wea else None\n",
        "        return self.propagate(edge_index, h=h, edge_attr=edge_embedding, h_attn=h_attn)\n",
        "\n",
        "    def message(self, h_j, edge_attr, h_attn_j, index: Tensor, ptr: OptTensor, size_i: Optional[int]):\n",
        "        h_attn = h_attn_j if h_attn_j is not None else h_j\n",
        "        h_attn = h_attn + edge_attr if self.wea else h_attn\n",
        "        # have to do part of this here instead of pre-computing a in forward because of missing edges in forward\n",
        "        # in our dags there is not much overlap in one convolution step, so not much overhead here\n",
        "        # and if attn transformation linear is applied in forward we'd have to consider full X/H matrices\n",
        "        # which in our case can be a lot larger\n",
        "        # BUT we could move it to forward similar to pyg GAT implementation\n",
        "        # ie apply two different linear to each respectively X/H, edge_attrs which yield a scalar each\n",
        "        # the in message only sum those up (to obtain a single scalar) and do softmax\n",
        "        a_j = self.attn_lin(h_attn)\n",
        "        a_j = softmax(a_j, index, ptr, size_i)\n",
        "        t = h_j * a_j\n",
        "        return t\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "class AttnConv(MessagePassing):\n",
        "    def __init__(self, attn_q_dim, emb_dim, attn_dim=0, num_relations=1, reverse=False):\n",
        "        super(AttnConv, self).__init__(aggr='add', flow='target_to_source' if reverse else 'source_to_target')\n",
        "\n",
        "        assert attn_q_dim > 0  # for us is not necessarily equal to attn dim at first RN layer\n",
        "        assert emb_dim > 0\n",
        "        attn_dim = attn_dim if attn_dim > 0 else emb_dim\n",
        "        if num_relations > 1:\n",
        "            self.wea = True\n",
        "            self.edge_encoder = torch.nn.Linear(num_relations, attn_dim)\n",
        "        else:\n",
        "            self.wea = False\n",
        "        self.attn_lin = nn.Linear(attn_q_dim + attn_dim, 1)\n",
        "\n",
        "    # h_attn_q is needed; h_attn, edge_attr are optional (we just use kwargs to be able to switch node aggregator above)\n",
        "    def forward(self, h, edge_index, h_attn_q=None, edge_attr=None, h_attn=None, **kwargs):\n",
        "        edge_embedding = self.edge_encoder(edge_attr) if self.wea else None\n",
        "        return self.propagate(edge_index, h_attn_q=h_attn_q, h=h, edge_attr=edge_embedding, h_attn=h_attn)\n",
        "\n",
        "    def message(self, h_attn_q_i, h_j, edge_attr, h_attn_j, index: Tensor, ptr: OptTensor, size_i: Optional[int]):\n",
        "        h_attn = h_attn_j if h_attn_j is not None else h_j\n",
        "        h_attn = h_attn + edge_attr if self.wea else h_attn\n",
        "        # see comment in above self attention why this is done here and not in forward\n",
        "        a_j = self.attn_lin(torch.cat([h_attn_q_i, h_attn], dim=-1))\n",
        "        a_j = softmax(a_j, index, ptr, size_i)\n",
        "        t = h_j * a_j\n",
        "        return t\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "class MultAttnConv(MessagePassing):\n",
        "    def __init__(self, attn_q_dim, emb_dim, attn_dim=0, num_relations=1, reverse=False):\n",
        "        super(MultAttnConv, self).__init__(aggr='add', flow='target_to_source' if reverse else 'source_to_target')\n",
        "\n",
        "        assert attn_q_dim > 0  # for us is not necessarily equal to attn dim at first RN layer\n",
        "        assert emb_dim > 0\n",
        "        attn_dim = attn_dim if attn_dim > 0 else emb_dim\n",
        "        if num_relations > 1:\n",
        "            self.wea = True\n",
        "            self.edge_encoder = torch.nn.Linear(num_relations, attn_dim)\n",
        "        else:\n",
        "            self.wea = False\n",
        "        self.attn_linl = nn.Linear(attn_q_dim, attn_q_dim)\n",
        "        self.attn_linr = nn.Linear(attn_dim, attn_q_dim)\n",
        "\n",
        "    # h_attn_q is needed; h_attn, edge_attr are optional (we just use kwargs to be able to switch node aggregator above)\n",
        "    def forward(self, h, edge_index, h_attn_q=None, edge_attr=None, h_attn=None, **kwargs):\n",
        "        edge_embedding = self.edge_encoder(edge_attr) if self.wea else None\n",
        "        return self.propagate(edge_index, h_attn_q=h_attn_q, h=h, edge_attr=edge_embedding, h_attn=h_attn)\n",
        "\n",
        "    def message(self, h_attn_q_i, h_j, edge_attr, h_attn_j, index: Tensor, ptr: OptTensor, size_i: Optional[int]):\n",
        "        h_attn = h_attn_j if h_attn_j is not None else h_j\n",
        "        h_attn = h_attn + edge_attr if self.wea else h_attn\n",
        "        # see comment in above self attention why this is done here and not in forward\n",
        "        a_j = torch.sum(self.attn_linl(h_attn_q_i) * self.attn_linr(h_attn), dim=1).unsqueeze(-1)\n",
        "        a_j = softmax(a_j, index, ptr, size_i)\n",
        "        t = h_j * a_j\n",
        "        return t\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "_Hx9ErkQYmV5"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DataParallel(torch.nn.DataParallel):\n",
        "    r\"\"\"Implements data parallelism at the module level.\n",
        "\n",
        "    This container parallelizes the application of the given :attr:`module` by\n",
        "    splitting a list of :class:`torch_geometric.data.Data` objects and copying\n",
        "    them as :class:`torch_geometric.data.Batch` objects to each device.\n",
        "    In the forward pass, the module is replicated on each device, and each\n",
        "    replica handles a portion of the input.\n",
        "    During the backwards pass, gradients from each replica are summed into the\n",
        "    original module.\n",
        "\n",
        "    The batch size should be larger than the number of GPUs used.\n",
        "\n",
        "    The parallelized :attr:`module` must have its parameters and buffers on\n",
        "    :obj:`device_ids[0]`.\n",
        "\n",
        "    .. note::\n",
        "\n",
        "        You need to use the :class:`torch_geometric.data.DataListLoader` for\n",
        "        this module.\n",
        "\n",
        "    Args:\n",
        "        module (Module): Module to be parallelized.\n",
        "        device_ids (list of int or torch.device): CUDA devices.\n",
        "            (default: all devices)\n",
        "        output_device (int or torch.device): Device location of output.\n",
        "            (default: :obj:`device_ids[0]`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, module, device_ids=None, output_device=None):\n",
        "        super(DataParallel, self).__init__(module, device_ids, output_device)\n",
        "        self.src_device = torch.device(\"cuda:{}\".format(self.device_ids[0])) if torch.cuda.is_available() else torch.device(\"cpu\")  # VT allow cpu\n",
        "\n",
        "    def forward(self, data_list):\n",
        "        \"\"\"\"\"\"\n",
        "        if len(data_list) == 0:\n",
        "            warnings.warn('DataParallel received an empty data list, which '\n",
        "                          'may result in unexpected behaviour.')\n",
        "            return None\n",
        "\n",
        "        if not self.device_ids or len(self.device_ids) == 1:  # Fallback\n",
        "            data = data_list[0].to(self.src_device)\n",
        "            return self.module(data)\n",
        "\n",
        "        for t in chain(self.module.parameters(), self.module.buffers()):\n",
        "            if t.device != self.src_device:\n",
        "                raise RuntimeError(\n",
        "                    ('Module must have its parameters and buffers on device '\n",
        "                     '{} but found one of them on device {}.').format(\n",
        "                         self.src_device, t.device))\n",
        "\n",
        "        inputs = self.scatter(data_list, self.device_ids)\n",
        "        replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n",
        "        outputs = self.parallel_apply(replicas, inputs, None)\n",
        "        return self.gather(outputs, self.output_device)\n",
        "\n",
        "    def scatter(self, data_list, device_ids):\n",
        "        num_devices = min(len(device_ids), len(data_list))\n",
        "\n",
        "        # count = torch.tensor([data.num_nodes for data in data_list])\n",
        "        # cumsum = count.cumsum(0)\n",
        "        # cumsum = torch.cat([cumsum.new_zeros(1), cumsum], dim=0)\n",
        "        # device_id = num_devices * cumsum.to(torch.float) / cumsum[-1].item()\n",
        "        # device_id = (device_id[:-1] + device_id[1:]) / 2.0\n",
        "        # device_id = device_id.to(torch.long)  # round.\n",
        "        # split = device_id.bincount().cumsum(0)\n",
        "        # split = torch.cat([split.new_zeros(1), split], dim=0)\n",
        "        # split = torch.unique(split, sorted=True)\n",
        "        # split = split.tolist()\n",
        "\n",
        "        return [\n",
        "            data_list[i].to(\n",
        "                torch.device('cuda:{}'.format(device_ids[i])))\n",
        "            for i in range(num_devices)\n",
        "        ]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx['train'] = r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HzeZ3FOAG2t",
        "outputId": "4fcb8e29-1b7f-4d02-bb09-c67fe0178849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([     0,      1,      2,  ..., 407973, 407974, 407975])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = list(range(1,30))\n",
        "v = list(range(31,60))\n",
        "i = list(range(61,90))"
      ],
      "metadata": {
        "id": "yt3_pbLbAexs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx['train'] = torch.tensor(t, dtype=None)\n",
        "split_idx['valid'] = torch.tensor(v, dtype=None)\n",
        "split_idx['test'] = torch.tensor(i, dtype=None)"
      ],
      "metadata": {
        "id": "hd9tpszMCrXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import augment_edge, encode_y_to_arr, decode_arr_to_seq\n",
        "from utils2 import ASTNodeEncoder2\n",
        "dataset.eval_metric = \"acc\"\n",
        "dataset.task_type = \"classification\"\n",
        "\n",
        "### set the transform function\n",
        "# augment_edge: add next-token edge as well as inverse edges. add edge attributes.\n",
        "# encode_y_to_arr: add y_arr to PyG data object, indicating the array representation of a sequence.\n",
        "# DAGNN\n",
        "augment = augment_edge2 if \"dagnn\" in gnn else augment_edge\n",
        "dataset.transform = transforms.Compose([augment])  #, lambda data: encode_y_to_arr(data)])\n",
        "\n",
        "\n",
        "\n",
        "nodetypes_mapping = pd.read_csv(os.path.join(dataset.root, 'mapping', 'typeidx2type.csv.gz'))\n",
        "nodeattributes_mapping = pd.read_csv(os.path.join(dataset.root, 'mapping', 'attridx2attr.csv.gz'))\n",
        "### Encoding node features into emb_dim vectors.\n",
        "### The following three node features are used.\n",
        "# 1. node type\n",
        "# 2. node attribute\n",
        "# 3. node depth\n",
        "node_encoder = ASTNodeEncoder2(emb_dim, num_nodetypes = len(nodetypes_mapping['type']), num_nodeattributes = len(nodeattributes_mapping['attr']), max_depth = 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo59Oh8PC59W",
        "outputId": "ea73ca60-e455-490f-c08a-8f1a2214e7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': tensor([61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78,\n",
              "         79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]),\n",
              " 'train': tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
              "         19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
              " 'valid': tensor([31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
              "         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(D, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "nwxu9td3WKmV"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e707dOmxXijs",
        "outputId": "473cafbb-66f9-497e-8864-1f632a64d73e"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[57058, 19], edge_index=[2, 107045], y=[57058, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader.dataset.edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O14u-wc8XjfU",
        "outputId": "ab771b26-6a87-425d-99e2-1a21fe505815"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0,     0,     0,  ..., 51989, 51990, 51990],\n",
              "        [ 2603,  2604,  2046,  ..., 32022, 35422, 37010]])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5fFMYVMWekFf",
        "outputId": "2812a5a7-add6-44d5-b250-156b3ae895ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's use 1 GPUs! -- DataParallel running also on CPU only\n",
            "=====Fold 1, Epoch 1\n",
            "Inside training module...\n",
            "Top sort Phase 1\n",
            "In top sort index  0\n",
            "Number of parent nodes  107045\n",
            "Number of unevaluated nodes  5119\n",
            "In top sort index  1\n",
            "Number of parent nodes  95207\n",
            "Number of unevaluated nodes  2668\n",
            "In top sort index  2\n",
            "Number of parent nodes  89265\n",
            "Number of unevaluated nodes  1118\n",
            "In top sort index  3\n",
            "Number of parent nodes  84099\n",
            "Number of unevaluated nodes  1947\n",
            "In top sort index  4\n",
            "Number of parent nodes  74804\n",
            "Number of unevaluated nodes  4776\n",
            "In top sort index  5\n",
            "Number of parent nodes  62185\n",
            "Number of unevaluated nodes  6541\n",
            "In top sort index  6\n",
            "Number of parent nodes  51012\n",
            "Number of unevaluated nodes  5965\n",
            "In top sort index  7\n",
            "Number of parent nodes  41468\n",
            "Number of unevaluated nodes  4429\n",
            "In top sort index  8\n",
            "Number of parent nodes  34541\n",
            "Number of unevaluated nodes  3486\n",
            "In top sort index  9\n",
            "Number of parent nodes  28648\n",
            "Number of unevaluated nodes  3169\n",
            "In top sort index  10\n",
            "Number of parent nodes  23582\n",
            "Number of unevaluated nodes  2976\n",
            "In top sort index  11\n",
            "Number of parent nodes  19130\n",
            "Number of unevaluated nodes  2794\n",
            "In top sort index  12\n",
            "Number of parent nodes  15559\n",
            "Number of unevaluated nodes  2223\n",
            "In top sort index  13\n",
            "Number of parent nodes  12775\n",
            "Number of unevaluated nodes  1734\n",
            "In top sort index  14\n",
            "Number of parent nodes  10632\n",
            "Number of unevaluated nodes  1328\n",
            "In top sort index  15\n",
            "Number of parent nodes  8746\n",
            "Number of unevaluated nodes  1099\n",
            "In top sort index  16\n",
            "Number of parent nodes  7030\n",
            "Number of unevaluated nodes  971\n",
            "In top sort index  17\n",
            "Number of parent nodes  5631\n",
            "Number of unevaluated nodes  820\n",
            "In top sort index  18\n",
            "Number of parent nodes  4432\n",
            "Number of unevaluated nodes  692\n",
            "In top sort index  19\n",
            "Number of parent nodes  3477\n",
            "Number of unevaluated nodes  555\n",
            "In top sort index  20\n",
            "Number of parent nodes  2718\n",
            "Number of unevaluated nodes  519\n",
            "In top sort index  21\n",
            "Number of parent nodes  2008\n",
            "Number of unevaluated nodes  512\n",
            "In top sort index  22\n",
            "Number of parent nodes  1390\n",
            "Number of unevaluated nodes  457\n",
            "In top sort index  23\n",
            "Number of parent nodes  880\n",
            "Number of unevaluated nodes  413\n",
            "In top sort index  24\n",
            "Number of parent nodes  502\n",
            "Number of unevaluated nodes  302\n",
            "In top sort index  25\n",
            "Number of parent nodes  258\n",
            "Number of unevaluated nodes  220\n",
            "In top sort index  26\n",
            "Number of parent nodes  102\n",
            "Number of unevaluated nodes  132\n",
            "In top sort index  27\n",
            "Number of parent nodes  42\n",
            "Number of unevaluated nodes  52\n",
            "In top sort index  28\n",
            "Number of parent nodes  8\n",
            "Number of unevaluated nodes  33\n",
            "In top sort index  29\n",
            "Number of parent nodes  1\n",
            "Number of unevaluated nodes  7\n",
            "In top sort index  30\n",
            "Number of parent nodes  0\n",
            "Number of unevaluated nodes  1\n",
            "Total nodes  =  57058\n",
            "Top sort Phase 2\n",
            "In top sort index  0\n",
            "Number of parent nodes  107045\n",
            "Number of unevaluated nodes  5121\n",
            "In top sort index  1\n",
            "Number of parent nodes  96909\n",
            "Number of unevaluated nodes  4441\n",
            "In top sort index  2\n",
            "Number of parent nodes  87483\n",
            "Number of unevaluated nodes  5518\n",
            "In top sort index  3\n",
            "Number of parent nodes  76772\n",
            "Number of unevaluated nodes  4211\n",
            "In top sort index  4\n",
            "Number of parent nodes  69981\n",
            "Number of unevaluated nodes  2657\n",
            "In top sort index  5\n",
            "Number of parent nodes  65448\n",
            "Number of unevaluated nodes  2015\n",
            "In top sort index  6\n",
            "Number of parent nodes  61580\n",
            "Number of unevaluated nodes  2370\n",
            "In top sort index  7\n",
            "Number of parent nodes  56697\n",
            "Number of unevaluated nodes  3304\n",
            "In top sort index  8\n",
            "Number of parent nodes  50208\n",
            "Number of unevaluated nodes  3597\n",
            "In top sort index  9\n",
            "Number of parent nodes  45362\n",
            "Number of unevaluated nodes  2700\n",
            "In top sort index  10\n",
            "Number of parent nodes  41306\n",
            "Number of unevaluated nodes  2749\n",
            "In top sort index  11\n",
            "Number of parent nodes  38071\n",
            "Number of unevaluated nodes  1775\n",
            "In top sort index  12\n",
            "Number of parent nodes  34728\n",
            "Number of unevaluated nodes  1908\n",
            "In top sort index  13\n",
            "Number of parent nodes  30705\n",
            "Number of unevaluated nodes  2112\n",
            "In top sort index  14\n",
            "Number of parent nodes  25484\n",
            "Number of unevaluated nodes  2334\n",
            "In top sort index  15\n",
            "Number of parent nodes  19692\n",
            "Number of unevaluated nodes  2289\n",
            "In top sort index  16\n",
            "Number of parent nodes  14298\n",
            "Number of unevaluated nodes  1989\n",
            "In top sort index  17\n",
            "Number of parent nodes  9875\n",
            "Number of unevaluated nodes  1602\n",
            "In top sort index  18\n",
            "Number of parent nodes  6597\n",
            "Number of unevaluated nodes  1269\n",
            "In top sort index  19\n",
            "Number of parent nodes  4228\n",
            "Number of unevaluated nodes  973\n",
            "In top sort index  20\n",
            "Number of parent nodes  2575\n",
            "Number of unevaluated nodes  751\n",
            "In top sort index  21\n",
            "Number of parent nodes  1468\n",
            "Number of unevaluated nodes  555\n",
            "In top sort index  22\n",
            "Number of parent nodes  762\n",
            "Number of unevaluated nodes  373\n",
            "In top sort index  23\n",
            "Number of parent nodes  375\n",
            "Number of unevaluated nodes  216\n",
            "In top sort index  24\n",
            "Number of parent nodes  168\n",
            "Number of unevaluated nodes  122\n",
            "In top sort index  25\n",
            "Number of parent nodes  66\n",
            "Number of unevaluated nodes  57\n",
            "In top sort index  26\n",
            "Number of parent nodes  29\n",
            "Number of unevaluated nodes  26\n",
            "In top sort index  27\n",
            "Number of parent nodes  12\n",
            "Number of unevaluated nodes  13\n",
            "In top sort index  28\n",
            "Number of parent nodes  5\n",
            "Number of unevaluated nodes  6\n",
            "In top sort index  29\n",
            "Number of parent nodes  1\n",
            "Number of unevaluated nodes  4\n",
            "In top sort index  30\n",
            "Number of parent nodes  0\n",
            "Number of unevaluated nodes  1\n",
            "Total nodes  =  57058\n",
            "Batch ===  Data(x=[57058, 19], edge_index=[2, 107045], y=[57058, 1])\n",
            "Before Pred\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-177-cefcf26ea4b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=====Fold {}, Epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;31m#valid_perf = eval(model, device, valid_loader, evaluator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#test_perf = eval(model, device, test_loader, evaluator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-175-423f6352de53>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, loader, optimizer, args, evaluator)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Before Pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pred done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-136-f4b8a50843de>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data_list)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ],
      "source": [
        "# start training \n",
        "import collections.abc as container_abcs\n",
        "int_classes = int\n",
        "from torch._six import  string_classes\n",
        "from dataloader import DataLoader\n",
        "start_fold = 1\n",
        "checkpoint_fn = \"\"\n",
        "train_results, valid_results, test_results = [], [], []     # on fold level\n",
        "\n",
        "for fold in range(start_fold, folds + 1):\n",
        "    # fold-specific settings & data splits\n",
        "    torch.manual_seed(fold)\n",
        "    random.seed(fold)\n",
        "    np.random.seed(fold)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(fold)\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    n_devices = torch.cuda.device_count() if torch.cuda.device_count() > 0 else 1\n",
        "    train_loader = DataLoader(D, batch_size=batch_size, shuffle=True,\n",
        "                              num_workers = num_workers)\n",
        "    valid_loader = DataLoader(D, batch_size=batch_size, shuffle=False,\n",
        "                              num_workers=num_workers)\n",
        "    test_loader = DataLoader(D, batch_size=batch_size, shuffle=False,\n",
        "                              num_workers=num_workers)\n",
        "\n",
        "    start_epoch = 1\n",
        "\n",
        "    # model etc.\n",
        "    model = init_model(args, node_encoder=None)\n",
        "\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs! -- DataParallel running also on CPU only\")\n",
        "    device_ids = list(range(torch.cuda.device_count())) if torch.cuda.device_count() > 0 else None\n",
        "    model = DataParallel(model, device_ids)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # overwrite some settings\n",
        "    if checkpointing and checkpoint:\n",
        "        # signal that it has been used\n",
        "        checkpoint = \"\"\n",
        "\n",
        "        results, start_epoch, model, optimizer = load_checkpoint(checkpoint_fn, model, optimizer)\n",
        "        train_results, valid_results, test_results, train_curve, valid_curve, test_curve = results\n",
        "        start_epoch += 1\n",
        "    else:\n",
        "        valid_curve, test_curve, train_curve = [], [], []\n",
        "\n",
        "    # start new epoch\n",
        "    for epoch in range(start_epoch, epochs + 1):\n",
        "        old_checkpoint_fn = checkpoint_fn\n",
        "        checkpoint_fn = '%s.pt' % os.path.join(dir_save, filename + \"_\" + str(fold) + \"_\" + str(epoch))\n",
        "\n",
        "        print(\"=====Fold {}, Epoch {}\".format(fold, epoch))\n",
        "        loss, train_perf = train(model, device, D, optimizer, args, evaluator=None)\n",
        "        #valid_perf = eval(model, device, valid_loader, evaluator)\n",
        "        #test_perf = eval(model, device, test_loader, evaluator)\n",
        "\n",
        "        print({'Train': train_perf, 'Validation': valid_perf, 'Test': test_perf})\n",
        "        #with open(train_file, 'a') as f:\n",
        "        #    f.write(\"{},{},{:.4f},{:.4f},{:.4f},{:.4f}\\n\".format(fold, epoch, loss, train_perf[dataset.eval_metric], valid_perf[dataset.eval_metric], test_perf[dataset.eval_metric]))\n",
        "\n",
        "        train_curve.append(train_perf[dataset.eval_metric])\n",
        "        #valid_curve.append(valid_perf[dataset.eval_metric])\n",
        "        #test_curve.append(test_perf[dataset.eval_metric])\n",
        "\n",
        "\n",
        "\n",
        "    print('Finished training for fold {} !'.format(fold)+\"*\"*20)\n",
        "    print('Best validation score: {}'.format(valid_curve[best_val_epoch]))\n",
        "    print('Test score: {}'.format(test_curve[best_val_epoch]))\n",
        "\n",
        "    with open(res_file, 'a') as f:\n",
        "        results = [fold, best_val_epoch, train_curve[best_val_epoch], valid_curve[best_val_epoch],test_curve[best_val_epoch]]\n",
        "        f.writelines(\",\".join([str(v) for v in results]) + \"\\n\")\n",
        "\n",
        "    train_results += [train_curve[best_val_epoch]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yU4Yd7wWdye"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1EHboRubR-C",
        "outputId": "0dc9ec3b-8985-4caf-d546-9e6e34cadfd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 63.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 730 kB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=ca9ea01206d8c8320b6c068fa522c7b80b3797737d9f71a1e3d131223a11e43a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-sparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eZV00Bwbcxx",
        "outputId": "97134a92-9408-45ca-fe29-4949493affbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.12.tar.gz (43 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▋                        | 10 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 20 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 30 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 969 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl size=1664876 sha256=19620db24027874ede83b309b615e0eb1f83a1d0b5b2ac43a53abf5df24abb20\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/e2/2f/44956c61e3299573ffe12da9d1374c7576ca0c5fb1fe1ed38c\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import remove_self_loops"
      ],
      "metadata": {
        "id": "JdrTa6KzbOLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import torch\n",
        "def top_sort(edge_index, graph_size):\n",
        "    node_ids = numpy.arange(graph_size, dtype=int)\n",
        "    node_order = numpy.zeros(graph_size, dtype=int)\n",
        "    unevaluated_nodes = numpy.ones(graph_size, dtype=bool)\n",
        "    parent_nodes = edge_index[0]\n",
        "    child_nodes = edge_index[1]\n",
        "    n = 0\n",
        "    while unevaluated_nodes.any():\n",
        "        # Find which parent nodes have not been evaluated\n",
        "        unevaluated_mask = unevaluated_nodes[parent_nodes]\n",
        "        # Find the child nodes of unevaluated parents\n",
        "        unready_children = child_nodes[unevaluated_mask]\n",
        "        # Mark nodes that have not yet been evaluated\n",
        "        # and which are not in the list of children with unevaluated parent nodes\n",
        "        nodes_to_evaluate = unevaluated_nodes & ~numpy.isin(node_ids, unready_children)\n",
        "        node_order[nodes_to_evaluate] = n\n",
        "        unevaluated_nodes[nodes_to_evaluate] = False\n",
        "        print('Depth = ', n)\n",
        "        n += 1\n",
        "    return torch.from_numpy(node_order).long()"
      ],
      "metadata": {
        "id": "UflILKikafVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge = numpy.loadtxt('/content/drive/MyDrive/sizing/all_vt_new/train/MegaBoom_edges.txt')\n",
        "x = numpy.loadtxt('/content/drive/MyDrive/sizing/all_vt_new/train/MegaBoom_node_x.txt')\n"
      ],
      "metadata": {
        "id": "w8SRUUVIazD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_tf = torch.Tensor(edge.T)\n",
        "#x_tf = torch.Tensor(x)\n",
        "ne = remove_self_loops(edge_tf)\n"
      ],
      "metadata": {
        "id": "crh40GGlkcoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw4FMxGXlP0o",
        "outputId": "2ff9541b-db56-4625-cff8-a5137a8c032e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1639294"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_tf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1wvo7xbl0TI",
        "outputId": "b3b1796a-ddd6-45e9-a58f-a22e3d14fb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4771206])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ne1 = ne[0].int()"
      ],
      "metadata": {
        "id": "GbuPvvZ2iemg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ne1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAVJ7-SUkqtW",
        "outputId": "e2adfb89-b04d-4d68-d391-38933d7802b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0,     0,     0,  ..., 51989, 51990, 51990],\n",
              "        [ 2603,  2604,  2046,  ..., 32022, 35422, 37010]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_order = top_sort(ne[0].int(), x.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7uPuqNTjjIC",
        "outputId": "39ca184c-9191-4be5-d2a2-29faf1e3690e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depth =  0\n",
            "Depth =  1\n",
            "Depth =  2\n",
            "Depth =  3\n",
            "Depth =  4\n",
            "Depth =  5\n",
            "Depth =  6\n",
            "Depth =  7\n",
            "Depth =  8\n",
            "Depth =  9\n",
            "Depth =  10\n",
            "Depth =  11\n",
            "Depth =  12\n",
            "Depth =  13\n",
            "Depth =  14\n",
            "Depth =  15\n",
            "Depth =  16\n",
            "Depth =  17\n",
            "Depth =  18\n",
            "Depth =  19\n",
            "Depth =  20\n",
            "Depth =  21\n",
            "Depth =  22\n",
            "Depth =  23\n",
            "Depth =  24\n",
            "Depth =  25\n",
            "Depth =  26\n",
            "Depth =  27\n",
            "Depth =  28\n",
            "Depth =  29\n",
            "Depth =  30\n",
            "Depth =  31\n",
            "Depth =  32\n",
            "Depth =  33\n",
            "Depth =  34\n",
            "Depth =  35\n",
            "Depth =  36\n",
            "Depth =  37\n",
            "Depth =  38\n",
            "Depth =  39\n",
            "Depth =  40\n",
            "Depth =  41\n",
            "Depth =  42\n",
            "Depth =  43\n",
            "Depth =  44\n",
            "Depth =  45\n",
            "Depth =  46\n",
            "Depth =  47\n",
            "Depth =  48\n",
            "Depth =  49\n",
            "Depth =  50\n",
            "Depth =  51\n",
            "Depth =  52\n",
            "Depth =  53\n",
            "Depth =  54\n",
            "Depth =  55\n",
            "Depth =  56\n",
            "Depth =  57\n",
            "Depth =  58\n",
            "Depth =  59\n",
            "Depth =  60\n",
            "Depth =  61\n",
            "Depth =  62\n",
            "Depth =  63\n",
            "Depth =  64\n",
            "Depth =  65\n",
            "Depth =  66\n",
            "Depth =  67\n",
            "Depth =  68\n",
            "Depth =  69\n",
            "Depth =  70\n",
            "Depth =  71\n",
            "Depth =  72\n",
            "Depth =  73\n",
            "Depth =  74\n",
            "Depth =  75\n",
            "Depth =  76\n",
            "Depth =  77\n",
            "Depth =  78\n",
            "Depth =  79\n",
            "Depth =  80\n",
            "Depth =  81\n",
            "Depth =  82\n",
            "Depth =  83\n",
            "Depth =  84\n",
            "Depth =  85\n",
            "Depth =  86\n",
            "Depth =  87\n",
            "Depth =  88\n",
            "Depth =  89\n",
            "Depth =  90\n",
            "Depth =  91\n",
            "Depth =  92\n",
            "Depth =  93\n",
            "Depth =  94\n",
            "Depth =  95\n",
            "Depth =  96\n",
            "Depth =  97\n",
            "Depth =  98\n",
            "Depth =  99\n",
            "Depth =  100\n",
            "Depth =  101\n",
            "Depth =  102\n",
            "Depth =  103\n",
            "Depth =  104\n",
            "Depth =  105\n",
            "Depth =  106\n",
            "Depth =  107\n",
            "Depth =  108\n",
            "Depth =  109\n",
            "Depth =  110\n",
            "Depth =  111\n",
            "Depth =  112\n",
            "Depth =  113\n",
            "Depth =  114\n",
            "Depth =  115\n",
            "Depth =  116\n",
            "Depth =  117\n",
            "Depth =  118\n",
            "Depth =  119\n",
            "Depth =  120\n",
            "Depth =  121\n",
            "Depth =  122\n",
            "Depth =  123\n",
            "Depth =  124\n",
            "Depth =  125\n",
            "Depth =  126\n",
            "Depth =  127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_order"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT5AzQiuku1v",
        "outputId": "76265aa4-c727-4d7d-ccdd-bdc48b1461ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "DAGNN_UM_v2_jpeg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}